{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b18af5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\adity\\anaconda3\\lib\\site-packages (1.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05131a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities for Each Class:\n",
      "buys_computer\n",
      "no     0.357143\n",
      "yes    0.642857\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided path\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\Book1.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Calculate prior probability for each class using groupby\n",
    "prior_probabilities = df.groupby('buys_computer').size() / len(df)\n",
    "\n",
    "# Display the result\n",
    "print(\"Prior Probabilities for Each Class:\")\n",
    "print(prior_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45213d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Conditional Density for 'Buys_Computer = no' given 'Age':\n",
      " age\n",
      "31…40    0.0\n",
      "<=30     0.6\n",
      ">40      0.4\n",
      "Name: no, dtype: float64\n",
      "Class Conditional Density for 'Buys_Computer = yes' given 'Age':\n",
      " age\n",
      "31…40    0.444444\n",
      "<=30     0.222222\n",
      ">40      0.333333\n",
      "Name: yes, dtype: float64\n",
      "\n",
      "Class Conditional Density for 'Buys_Computer = no' given 'Income':\n",
      " income\n",
      "high       0.4\n",
      "low        0.2\n",
      "medium     0.4\n",
      "Name: no, dtype: float64\n",
      "Class Conditional Density for 'Buys_Computer = yes' given 'Income':\n",
      " income\n",
      "high       0.333333\n",
      "low        0.333333\n",
      "medium     0.333333\n",
      "Name: yes, dtype: float64\n",
      "\n",
      "Class Conditional Density for 'Buys_Computer = no' given 'Student':\n",
      " student\n",
      "no     0.8\n",
      "yes    0.2\n",
      "Name: no, dtype: float64\n",
      "Class Conditional Density for 'Buys_Computer = yes' given 'Student':\n",
      " student\n",
      "no     0.333333\n",
      "yes    0.666667\n",
      "Name: yes, dtype: float64\n",
      "\n",
      "Class Conditional Density for 'Buys_Computer = no' given 'Credit_Rating':\n",
      " credit_rating\n",
      "excellent    0.6\n",
      "fair         0.4\n",
      "Name: no, dtype: float64\n",
      "Class Conditional Density for 'Buys_Computer = yes' given 'Credit_Rating':\n",
      " credit_rating\n",
      "excellent    0.333333\n",
      "fair         0.666667\n",
      "Name: yes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset from Excel\n",
    "file_path = \"C:/Users/adity/Downloads/Book1.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Function to calculate class conditional densities for a given feature\n",
    "def calculate_class_conditional_density(feature, target_class):\n",
    "    counts = df.groupby([feature, 'buys_computer']).size().unstack().fillna(0)\n",
    "    class_conditional_density = counts[target_class] / counts[target_class].sum()\n",
    "    return class_conditional_density\n",
    "\n",
    "# Calculate class conditional densities for each feature\n",
    "age_cond_density_no = calculate_class_conditional_density('age', 'no')\n",
    "age_cond_density_yes = calculate_class_conditional_density('age', 'yes')\n",
    "\n",
    "income_cond_density_no = calculate_class_conditional_density('income', 'no')\n",
    "income_cond_density_yes = calculate_class_conditional_density('income', 'yes')\n",
    "\n",
    "student_cond_density_no = calculate_class_conditional_density('student', 'no')\n",
    "student_cond_density_yes = calculate_class_conditional_density('student', 'yes')\n",
    "\n",
    "credit_rating_cond_density_no = calculate_class_conditional_density('credit_rating', 'no')\n",
    "credit_rating_cond_density_yes = calculate_class_conditional_density('credit_rating', 'yes')\n",
    "\n",
    "# Print results\n",
    "print(\"Class Conditional Density for 'Buys_Computer = no' given 'Age':\\n\", age_cond_density_no)\n",
    "print(\"Class Conditional Density for 'Buys_Computer = yes' given 'Age':\\n\", age_cond_density_yes)\n",
    "\n",
    "print(\"\\nClass Conditional Density for 'Buys_Computer = no' given 'Income':\\n\", income_cond_density_no)\n",
    "print(\"Class Conditional Density for 'Buys_Computer = yes' given 'Income':\\n\", income_cond_density_yes)\n",
    "\n",
    "print(\"\\nClass Conditional Density for 'Buys_Computer = no' given 'Student':\\n\", student_cond_density_no)\n",
    "print(\"Class Conditional Density for 'Buys_Computer = yes' given 'Student':\\n\", student_cond_density_yes)\n",
    "\n",
    "print(\"\\nClass Conditional Density for 'Buys_Computer = no' given 'Credit_Rating':\\n\", credit_rating_cond_density_no)\n",
    "print(\"Class Conditional Density for 'Buys_Computer = yes' given 'Credit_Rating':\\n\", credit_rating_cond_density_yes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7239dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared statistic: 1.1549999999999998\n",
      "P-value: 0.8854505348655846\n",
      "\n",
      "Significance level: 0.05\n",
      "Fail to reject the null hypothesis. There is no evidence of dependence between the features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Load the dataset from the provided path\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\Book1.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Features for testing independence\n",
    "features = ['age', 'income', 'student', 'credit_rating']\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(index=df['age'], columns=df['income'])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Chi-squared statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "print(f\"\\nSignificance level: {alpha}\")\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis. There is evidence of dependence between the features.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no evidence of dependence between the features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6caa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naïve-Bayes classifier: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from the provided path\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\Book1.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'buys_computer' is the target variable\n",
    "X = df.drop('buys_computer', axis=1)\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Define categorical columns for encoding\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and Gaussian Naïve-Bayes model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Tr_X, Te_X, Tr_y, Te_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using the pipeline\n",
    "model.fit(Tr_X, Tr_y)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.score(Te_X, Te_y)\n",
    "print(f\"Accuracy of the Naïve-Bayes classifier: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354f6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "# Replace 'C:\\\\Users\\\\adity\\\\Downloads\\\\t5_train (2).xlsx' with the actual file path\n",
    "df = pd.read_excel('C:\\\\Users\\\\adity\\\\Downloads\\\\t5_train (2).xlsx')\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'embed_1'  # Replace with the actual name of your target column\n",
    "\n",
    "# Check if the target column is present in the DataFrame\n",
    "if target_column in df.columns:\n",
    "    # Use LabelEncoder to transform the target column\n",
    "    le = LabelEncoder()\n",
    "    df[target_column] = le.fit_transform(df[target_column])\n",
    "\n",
    "    # Assuming you have other feature columns\n",
    "    # Replace 'feature_columns' with the actual list of feature columns\n",
    "    feature_columns = ['embed_2', 'embed_3', 'embed_4', 'embed_5', 'embed_6']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[feature_columns], df[target_column], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create a RandomForestClassifier (you can choose a different model)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{target_column}' not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc957f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
